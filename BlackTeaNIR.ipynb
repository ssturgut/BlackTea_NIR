{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "import plotly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats, signal\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "from scipy.signal import savgol_filter, general_gaussian\n",
    "from scipy.signal import detrend as scipydetrend\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import f, chi2, norm, sem\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from obspy.signal import detrend as obspydetrend\n",
    "from verstack.stratified_continuous_split import scsplit\n",
    "import os\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScatterCorrection():\n",
    "\n",
    "  def Normalisation(input_data):\n",
    "\n",
    "    if 'sample' in input_data.columns:\n",
    "      start=1\n",
    "    else:\n",
    "      start=0\n",
    "\n",
    "    data_normal=StandardScaler().fit_transform(input_data.iloc[:,start:])\n",
    "    data_normal=pd.DataFrame(data_normal, index=input_data['sample'] if 'sample' in input_data.columns else input_data.index, columns=input_data.columns[start:])\n",
    "\n",
    "    return (data_normal)  \n",
    "\n",
    "  def SNV(input_data):\n",
    "      ''' Perform Standard Normal Variate scatter correction.\n",
    "\n",
    "      There are two methods to be choosen (1) MSC and (2) SNV. \n",
    "      For SNV, the only function parameter is data frame which needs to be defined.\n",
    "      For MSC, the user can choose some options apart from data frame as:\n",
    "      - method='MSC' (default), 'IMSC' \n",
    "      - meancentering= None (default), 'all', 'group' \n",
    "      - reference= a external reference can be loaded. Otherwise mean of the data set will be used ('mean').'''\n",
    "\n",
    "      #clean '.*' extensions of sample names\n",
    "      #for i in range(len(input_data['sample'])):\n",
    "       # input_data['sample'][i]=input_data['sample'][i][:-6]    \n",
    "      #input_data=input_data.set_index('sample')\n",
    "      \n",
    "      # Define a new array and populate it with the corrected data    \n",
    "      data_snv = pd.DataFrame().reindex_like(input_data)\n",
    "      if 'sample' in input_data.columns:\n",
    "        data_snv['sample']=input_data['sample']\n",
    "        data_snv=data_snv.set_index('sample')\n",
    "        start=1\n",
    "      else:\n",
    "        start=0\n",
    "\n",
    "      for i in range(input_data.shape[0]):\n",
    "        # Apply correction\n",
    "        data_snv.iloc[i,:] = (input_data.iloc[i,start:] - np.mean(input_data.iloc[i,start:])) / np.std(input_data.iloc[i,start:])\n",
    "      \n",
    "      #input_data=input_data.set_index(input_data.index)\n",
    "      return (data_snv)  \n",
    "\n",
    "  def MSC(input_data, method='MSC', meancentering='all', reference='mean'):\n",
    "      ''' Perform Multiplicative scatter correction\n",
    "      \n",
    "      There are two methods to be choosen (1) MSC and (2) SNV. \n",
    "      For SNV, the only function parameter is data frame which needs to be defined.\n",
    "      For MSC, the user can choose some options apart from data frame as:\n",
    "      - method='MSC' (default), 'IMSC' \n",
    "      - meancentering= None (default), 'all', 'group' \n",
    "      - reference= a external reference can be loaded. Otherwise mean of the data set will be used 'mean' or 'median'.'''\n",
    "\n",
    "      #clean '.*' extensions of sample names\n",
    "      #for i in range(len(input_data['sample'])):\n",
    "        #input_data['sample'][i]=input_data['sample'][i][:-6]\n",
    "      \n",
    "      # mean centre correction is none\n",
    "      if meancentering==None:\n",
    "        input_data=input_data.set_index('sample')\n",
    "      # mean centre correction according to the sample group label\n",
    "      elif meancentering=='group':      \n",
    "        df_mean=input_data.groupby(['sample']).mean()\n",
    "        input_data=input_data.set_index('sample')\n",
    "        for name in df_mean.index:\n",
    "          input_data.loc[name]=input_data.loc[name]-df_mean.loc[name]\n",
    "      # mean centre correction using all spectra irrespective of sample groups\n",
    "      elif meancentering=='all':\n",
    "        if 'sample' in input_data.columns:\n",
    "          input_data=input_data.set_index('sample')\n",
    "        if reference == 'mean':\n",
    "          for i in range(input_data.shape[0]):\n",
    "            input_data.iloc[i,:] -= input_data.iloc[i,:].mean()\n",
    "        elif reference == 'median':\n",
    "          for i in range(input_data.shape[0]):\n",
    "            input_data.iloc[i,:] -= input_data.iloc[i,:].median()\n",
    "\n",
    "      # Get the reference spectrum. If not given, estimate it from the mean   \n",
    "      if reference == 'mean':    \n",
    "          # Calculate mean\n",
    "          ref = input_data.mean()\n",
    "      elif reference == 'median': \n",
    "          ref = input_data.median()\n",
    "      else:\n",
    "          ref = reference\n",
    "\n",
    "      # Define a new array and populate it with the corrected data    \n",
    "      data_msc = pd.DataFrame().reindex_like(input_data)\n",
    "      if 'sample' in input_data.columns:\n",
    "        data_msc['sample']=input_data['sample']\n",
    "        data_msc=data_msc.set_index('sample')\n",
    "        start=1\n",
    "      else:\n",
    "        start=0\n",
    "\n",
    "      for i in range(input_data.shape[0]):\n",
    "        # Run regression\n",
    "        X = ref.values.reshape(-1, 1)  # values converts it into a numpy array\n",
    "        y = input_data.iloc[1,start:].values.reshape(-1, 1)\n",
    "        linear_regressor = LinearRegression()  # create object for the class\n",
    "        if method=='MSC': \n",
    "          linear_regressor.fit(X=X, y=y)  # perform linear regression for MSC\n",
    "        elif method=='IMSC': \n",
    "          linear_regressor.fit(X=y, y=X)  # perform linear regression for Inverted MSC\n",
    "          # Apply correction\n",
    "        data_msc.iloc[i,:] = (input_data.iloc[i,start:] - linear_regressor.intercept_[0]) / linear_regressor.coef_[0]\n",
    "      \n",
    "      return (data_msc) \n",
    "  \n",
    "  def MinMaxNorm(input_data):\n",
    "    # copy the data\n",
    "    df_min_max_scaled = input_data.copy()\n",
    "  \n",
    "    # apply normalization techniques\n",
    "    if 'sample' in input_data.columns:\n",
    "      for column in df_min_max_scaled.columns[df_min_max_scaled.columns != 'sample']:\n",
    "        df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())\n",
    "    else: \n",
    "      for column in df_min_max_scaled.columns:\n",
    "        df_min_max_scaled[column] = (df_min_max_scaled[column] - df_min_max_scaled[column].min()) / (df_min_max_scaled[column].max() - df_min_max_scaled[column].min())\n",
    "    \n",
    "    return (df_min_max_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SmoothandDeriv():\n",
    "  def RemoveSpike(input_data, kernelsize):\n",
    "    despiked=input_data.copy()\n",
    "\n",
    "    if 'sample' in input_data.columns:\n",
    "      despiked['sample']=input_data['sample']\n",
    "      despiked=despiked.set_index('sample')\n",
    "      start=1\n",
    "    else:\n",
    "      start=0\n",
    "\n",
    "    for i in range(0, input_data.shape[0]):\n",
    "      despiked.iloc[i,start:] = signal.medfilt(input_data.iloc[i,start:], kernelsize)\n",
    "\n",
    "    return (despiked)\n",
    "\n",
    "  def Derivative(input_data,method='central'):\n",
    "      '''Compute the first derivative of the spectras.\n",
    "\n",
    "      Returns\n",
    "      -------\n",
    "      float\n",
    "          Difference formula:\n",
    "              central: f(a+h) - f(a-h))/2h\n",
    "              forward: f(a+h) - f(a))/h\n",
    "              backward: f(a) - f(a-h))/h            \n",
    "      '''\n",
    "\n",
    "      if 'sample' not in input_data.columns:\n",
    "        input_data.insert(0, 'sample', input_data.index)\n",
    "\n",
    "      df = pd.DataFrame().reindex_like(input_data)\n",
    "      df.iloc[:,:]=input_data.iloc[:,:]\n",
    "\n",
    "      #global df_derivates\n",
    "      df_derivates = pd.DataFrame(columns=df.columns[:-1])\n",
    "      df_derivates['sample']=df['sample']\n",
    "  \n",
    "      if method == 'central':\n",
    "        for row in range(len(df['sample'])):\n",
    "          for col in range(len(df.columns[1:])-2):\n",
    "            df_derivates.iloc[row,col+1]=(df.iloc[row, col+3]-df.iloc[row, col+1])/(float(df.columns[col+3])-float(df.columns[col+1]))\n",
    "      elif method == 'forward':\n",
    "        for row in range(len(df['sample'])):\n",
    "          for col in range(len(df.columns[1:])-1):\n",
    "            df_derivates.iloc[row,col+1]=(df.iloc[row, col+2]-df.iloc[row, col+1])/(float(df.columns[col+2])-float(df.columns[col+1]))\n",
    "      elif method == 'backward':\n",
    "        for row in range(len(df['sample'])):\n",
    "          for col in range(len(df.columns[1:])-1):\n",
    "            df_derivates.iloc[row,col+1]=(df.iloc[row, col+1]-df.iloc[row, col+2])/(float(df.columns[col+2])-float(df.columns[col+1]))\n",
    "      else:\n",
    "          raise ValueError(\"Method must be 'central', 'forward' or 'backward'.\")\n",
    "      \n",
    "      return (df_derivates.dropna(axis=1, how='all', )) \n",
    "  \n",
    "  def SG(input_data, window=5, polyorder=2, derivorder=1):\n",
    "    '''Applies Savitzky-Golay Filter to the given data.\n",
    "    - window: window length is similar moving window smoothing but this is the number of data to be fitted to polynomial func. (give an odd number)\n",
    "    - polyorder: order of polynomil function which the data is fitted.\n",
    "    - derivorder: it is the degree/order or numerical derivation after smoothing.'''\n",
    "    \n",
    "    smoothdata = pd.DataFrame().reindex_like(input_data)\n",
    "\n",
    "    if 'sample' in input_data.columns:\n",
    "      smoothdata['sample']=input_data['sample']\n",
    "      smoothdata=smoothdata.set_index('sample')\n",
    "      start=1\n",
    "    else:\n",
    "      start=0\n",
    "\n",
    "    for i in range(0,data.shape[0],1):\n",
    "      smoothdata.iloc[i,0:] = savgol_filter(input_data.iloc[i,start:], window_length=window, polyorder = polyorder, deriv=derivorder)\n",
    "    \n",
    "    return (smoothdata)\n",
    "\n",
    "  def NW(input_data, window=3, derivorder=1):  \n",
    "    '''Applies Norris-Williams Filter to the given data.\n",
    "    - window: window length is similar moving window smoothing but this is the number of data to be included in smooting and derivation. (give an odd number)\n",
    "    - derivorder: it is the degree/order or numerical derivation after smoothing.'''    \n",
    "    if (window % 2) == 0:\n",
    "      return(print ('Window size needs to be an odd number!'))\n",
    "\n",
    "    smoothdata = pd.DataFrame().reindex_like(input_data)\n",
    "    if 'sample' in input_data.columns:\n",
    "      smoothdata['sample']=input_data['sample']\n",
    "      smoothdata=smoothdata.set_index('sample')\n",
    "      start=1\n",
    "    else:\n",
    "      start=0\n",
    "    \n",
    "    # the first step (smoothing) of the norris-williams derivation\n",
    "    for k in range(0,input_data.shape[0],1):\n",
    "      i = 0\n",
    "      print('smoothing sample-'+str(k))\n",
    "      while i < input_data.shape[1] - window + 1:\n",
    "          smoothdata.iloc[k,i+math.floor(window/2)] = sum(input_data.iloc[k, i+start : i+start+ window -1]) / (window+1)\n",
    "          i += 1\n",
    "    smoothdata = smoothdata.iloc[:,math.floor(window/2):-math.floor(window/2)]\n",
    "\n",
    "    # the second step (derivation) of the norris-williams derivation\n",
    "    derivdata = pd.DataFrame().reindex_like(smoothdata)\n",
    "    for k in range(0,smoothdata.shape[0],1):\n",
    "      i = 0\n",
    "      print('derivating sample-'+str(k))\n",
    "      if derivorder == 1:\n",
    "        while i < smoothdata.shape[1] - window + 1:\n",
    "          derivdata.iloc[k,i+math.floor(window/2)] = (smoothdata.iloc[k, i] - smoothdata.iloc[k, i+window-1])\n",
    "          i += 1\n",
    "        #return (smoothdata.iloc[:,math.floor(window/2):-math.floor(window/2)])\n",
    "      if derivorder == 2:\n",
    "        while i < smoothdata.shape[1] - window + 1:\n",
    "          derivdata.iloc[k,i+math.floor(window/2)] = (smoothdata.iloc[k, i+start] - 2*smoothdata.iloc[k, i+math.floor(window/2)] + smoothdata.iloc[k, i+window-1])\n",
    "          i += 1\n",
    "        #return (smoothdata.iloc[:,2*math.floor(window/2):-2*math.floor(window/2)]) \n",
    "    return (derivdata.iloc[:,math.floor(window/2):-math.floor(window/2)])    \n",
    "\n",
    "\n",
    "def deTrend(input_data, method='linregres', order=None, spline_gap=None, plot=False):\n",
    "  '''Applies detrending to the given data.\n",
    "  - method: 'linregres', fits a linear func to the spectrum and removes the signal from the regression line.\n",
    "  'meansubstract', mean centers the data using th mean af a spectra.\n",
    "  'highorder', fits a >= 2nd order polynomial funstion to the data and takes the diffrecence. if the order is 1, 'highorder' and 'linregres' is almost identical.\n",
    "  'simple', draws a line between first and last points of the spectrum and takes the diference of this line and the signal.\n",
    "  'spline', fits multpline polynomial fnctions for each spline_gap number of data with the given order and takes the difference.\n",
    "  - order: the order of fitted polynomial function for highorder and spline methods.\n",
    "  - plot: True or False only for for highorder and spline methods. '''\n",
    "  \n",
    "  detrenddata = pd.DataFrame().reindex_like(input_data)\n",
    "  if 'sample' in input_data.columns:\n",
    "    detrenddata['sample']=input_data['sample']\n",
    "    detrenddata=detrenddata.set_index('sample')\n",
    "    start=1\n",
    "  else:\n",
    "    start=0\n",
    "  \n",
    "  if method=='linregres':\n",
    "    for i in range(0,data.shape[0],1):\n",
    "      detrenddata.iloc[i,0:] = scipydetrend(input_data.iloc[i,start:], type='linear')\n",
    "  elif method=='meansubstract':\n",
    "    for i in range(0,data.shape[0],1):\n",
    "       detrenddata.iloc[i,0:] = scipydetrend(input_data.iloc[i,start:], type='constant')\n",
    "  elif method=='highorder':\n",
    "    for i in range(0,data.shape[0],1):\n",
    "      detrenddata.iloc[i,0:] = obspydetrend.polynomial(input_data.iloc[i,start:], order=order, plot=plot if i==data.shape[0]-1 else False)\n",
    "  elif method=='simple':\n",
    "    for i in range(0,data.shape[0],1):\n",
    "      detrenddata.iloc[i,0:] = obspydetrend.simple(input_data.iloc[i,start:])\n",
    "  elif method=='spline':\n",
    "    for i in range(0,data.shape[0],1):\n",
    "      detrenddata.iloc[i,0:] = obspydetrend.spline(data.iloc[0,1:], order=order, dspline=spline_gap, plot=plot if i==data.shape[0]-1 else False) \n",
    "\n",
    "  return (detrenddata)\n",
    "\n",
    "\n",
    "\n",
    "def RMS_repeatability(input_data, central='mean', conf=0.95, multiplicator=1e6, reducename=False, reducechar=6):\n",
    "   \"this function calculates RMS, STDlimit and lists samples to be repeated\"\n",
    "\n",
    "   df = pd.DataFrame().reindex_like(input_data)\n",
    "   df.iloc[:,:]=input_data.iloc[:,:]\n",
    "\n",
    "   global results\n",
    "   if reducename==True:\n",
    "     for i in range(len(df['sample'])):\n",
    "       df['sample'][i]=df['sample'][i][:-reducechar]\n",
    "\n",
    "   if central =='mean':\n",
    "     df_mean=df.groupby(['sample']).mean()\n",
    "   elif central =='median':\n",
    "     df_mean=df.groupby(['sample']).median()\n",
    "   df=df.set_index('sample')\n",
    " \n",
    "   df_subs=df\n",
    "   for name in df_mean.index:\n",
    "     df_subs.loc[name]=df.loc[name]-df_mean.loc[name]\n",
    "  \n",
    "   df['RMS']=multiplicator*np.sqrt(np.square(df_subs).mean(axis='columns'))\n",
    "   RMS_mean=np.sqrt(np.square(df).groupby(by=['sample']).mean())['RMS']\n",
    "\n",
    "   c = Counter(df.index) \n",
    "   STD=RMS_mean\n",
    "   for name in RMS_mean.index:\n",
    "     STD.loc[name]=RMS_mean.loc[name]*np.sqrt(c[name]/(c[name]-1))\n",
    "  \n",
    "   STD_limit=np.sqrt(np.square(STD).mean(axis='rows'))* stats.t.ppf(conf, len(STD))\n",
    "\n",
    "   results=pd.DataFrame(columns=['RMS', 'STDLimit','Acceptability'], index=df.index)\n",
    "   results['RMS']=round(df['RMS'],2)\n",
    "   results['STDLimit']=round(STD_limit,2)\n",
    "   results['Acceptability']=results['RMS']<STD_limit\n",
    "   booleanDictionary = {True: 'Accept', False: '* Repeat'}\n",
    "   results['Acceptability'] = results['Acceptability'] .replace(booleanDictionary)\n",
    "   pd.set_option('display.max_rows', None)\n",
    "   \n",
    "   return(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def RMS_graph(results):    \n",
    "   \"this function creates a graph to visualise RMS, STDlimit and samples to be repeated\"\n",
    "   \n",
    "   fig1 = px.scatter(y=results['RMS'],  color=results['Acceptability'], symbol = results['Acceptability'] )\n",
    "   fig2 = px.line( y=results['STDLimit'])    \n",
    "    \n",
    "   fig2.update_traces(line_color='firebrick')\n",
    "   fig3 = go.Figure(data=fig1.data + fig2.data)\n",
    "   fig3.update_traces(marker_size=5, showlegend=False)\n",
    "   fig3.update_layout(\n",
    "       title=\"NIR Repetability Test Results\",\n",
    "       yaxis_title=\"<b>Root Mean Square (x10)</b>\",\n",
    "       xaxis_title=\"<b>Tea Samples</b>\",\n",
    "       xaxis=dict(\n",
    "           showgrid=True,\n",
    "           showline=True,\n",
    "           showticklabels=False,\n",
    "           ticks='outside',\n",
    "           tickcolor='rgb(102, 102, 102)',\n",
    "           linecolor='rgb(102, 102, 102)',\n",
    "       ),       \n",
    "       yaxis=dict(\n",
    "           showgrid=True,\n",
    "           showline=True,\n",
    "           showticklabels=True,\n",
    "           ticks='outside',\n",
    "           tickcolor='rgb(102, 102, 102)',\n",
    "           linecolor='rgb(102, 102, 102)',\n",
    "       ),\n",
    "       #font=dict(size=5),\n",
    "       margin=dict(l=40, r=40, b=40, t=40),\n",
    "       paper_bgcolor='white',\n",
    "       plot_bgcolor='white',\n",
    "       width=300, height=300,\n",
    "   )\n",
    "\n",
    "   fig3.show()\n",
    "   return(fig3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def DrawSpect(input_data):\n",
    "  fig = go.Figure()\n",
    "\n",
    "  if 'sample' in input_data.columns:\n",
    "    names=input_data['sample'].values\n",
    "    start=1\n",
    "  else:\n",
    "    names=input_data.index\n",
    "    start=0\n",
    "\n",
    "  for i in range(0,input_data.shape[0],1):\n",
    "    fig.add_trace(go.Scatter(x=input_data.columns[start:].values.astype(float), y=input_data.iloc[i,start:], mode='lines', name=str(names[i])))\n",
    " \n",
    "  fig.update_traces(marker_size=3)\n",
    "  fig.update_layout(\n",
    "      title=\"NIR Spectras\",\n",
    "      yaxis_title=\"<b>log(1/R)</b>\",\n",
    "      xaxis_title=\"<b>Wavelength (nm)</b>\",\n",
    "      xaxis=dict(\n",
    "          showgrid=True,\n",
    "          showline=True,\n",
    "          showticklabels=True,\n",
    "          ticks='outside',\n",
    "          tickcolor='rgb(102, 102, 102)',\n",
    "          linecolor='rgb(102, 102, 102)',\n",
    "          tickmode = 'linear',\n",
    "          #tick0 = 0.5,\n",
    "          dtick = 200,\n",
    "      ),\n",
    "      yaxis=dict(\n",
    "          showgrid=True,\n",
    "          showline=True,\n",
    "          showticklabels=True,\n",
    "          ticks='outside',\n",
    "          tickcolor='rgb(102, 102, 102)',\n",
    "          linecolor='rgb(102, 102, 102)',\n",
    "          #tickmode = 'linear',\n",
    "          #tick0 = 0.5,\n",
    "          #dtick = 0.1\n",
    "      ),    \n",
    "      margin=dict(l=40, r=40, b=40, t=40),\n",
    "      paper_bgcolor='white',\n",
    "      plot_bgcolor='white',\n",
    "      width=600, height=400,\n",
    "  ) \n",
    " \n",
    "  fig.show()\n",
    "  return(fig)\n",
    "\n",
    "\n",
    "\n",
    "class PCR:\n",
    "\n",
    "  def Outliers(X, y, pc, criteria='chisq', conf=0.95):\n",
    "    ''' criteria: 'chisq','zdist', '3std', '4std', 'average' '''\n",
    "    #pc=5\n",
    "    # Define the PCA object and fit transform\n",
    "    pca = PCA()\n",
    "    T = pca.fit_transform(X)\n",
    "\n",
    "    # fit a Minimum Covariance Determinant (MCD) robust estimator to data \n",
    "    robust_cov = MinCovDet().fit(T[:,:pc])\n",
    " \n",
    "    # Get the Mahalanobis distance\n",
    "    mahala = robust_cov.mahalanobis(T[:,:pc])\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=T[:, 0], y=T[:, 1], mode='markers+text',\n",
    "                          name='R2', marker_color=mahala, text=np.round(mahala[:],2) , textposition=\"top center\"))\n",
    "    fig.update_layout(\n",
    "          title=\"PCA Score Plot and Mahalanobis distance\",\n",
    "          yaxis_title= \"PC2 (\" + str(np.round(pca.explained_variance_ratio_[1]*100,2)) +\"%)\" ,\n",
    "          xaxis_title=\"PC1 (\" + str(np.round(pca.explained_variance_ratio_[0]*100,2)) +\"%)\" ,\n",
    "          xaxis=dict(\n",
    "              showgrid=True,\n",
    "              showline=True,\n",
    "              showticklabels=True,\n",
    "              ticks='outside',\n",
    "              tickcolor='rgb(102, 102, 102)',\n",
    "              linecolor='rgb(102, 102, 102)',\n",
    "          ),\n",
    "          yaxis=dict(\n",
    "              showgrid=True,\n",
    "              showline=True,\n",
    "              showticklabels=True,\n",
    "              ticks='outside',\n",
    "              tickcolor='rgb(102, 102, 102)',\n",
    "              linecolor='rgb(102, 102, 102)',\n",
    "          ),    \n",
    "          margin=dict(l=140, r=40, b=50, t=80),\n",
    "          paper_bgcolor='white',\n",
    "          plot_bgcolor='white',\n",
    "          width=400, height=400,\n",
    "        )\n",
    "    fig.show()\n",
    "\n",
    "    fig_mahala = go.Figure()\n",
    "    mahala_name_criteria=np.full((len(mahala)), mahala.mean()+sem(mahala)*norm.ppf(conf))\n",
    "    fig_mahala.add_trace(go.Scatter(y=mahala, x=np.linspace(1, len(mahala)), mode='markers+text', marker_line_width=2, \n",
    "                                    text=np.where(mahala_name_criteria>mahala,'',X.index), textposition=\"middle right\",\n",
    "                                    marker=dict(color=mahala)))  \n",
    "    fig_mahala.update_traces(showlegend=False)\n",
    "    if criteria=='average':\n",
    "        fig_mahala.add_trace(go.Scatter(y=[mahala.mean(), mahala.mean()], x=[1, len(mahala)], mode='lines', name='Average Mahalanobis Distance',\n",
    "                                    line=dict(color='red', width=2, dash='dash')))\n",
    "    if criteria=='zdist':\n",
    "        fig_mahala.add_trace(go.Scatter(y=[mahala.mean()+sem(mahala)*norm.ppf(conf), mahala.mean()+sem(mahala)*norm.ppf(conf)],\n",
    "                                    x=[1, len(mahala)], mode='lines', name=str(conf) + ' Probability (z-dist)',\n",
    "                                    line=dict(color='red', width=2, dash='dash')))\n",
    "    if criteria=='chisq':\n",
    "        fig_mahala.add_trace(go.Scatter(y=[chi2.ppf((1-conf), df=len(mahala)-1,), chi2.ppf((1-conf), df=len(mahala)-1,)],\n",
    "                                    x=[1, len(mahala)], mode='lines', name=str(conf) + ' Probability (chi<sup>2</sup> dist)',\n",
    "                                    line=dict(color='red', width=2, dash='dash')))\n",
    "    if criteria=='3std':\n",
    "        fig_mahala.add_trace(go.Scatter(y=[mahala.mean()+3*mahala.std(), mahala.mean()+3*mahala.std()], \n",
    "                                    x=[1, len(mahala)], mode='lines', name=str(conf) + ' Probability (+3 std)',\n",
    "                                    line=dict(color='red', width=2, dash='dash')))\n",
    "    if criteria=='4std':\n",
    "        fig_mahala.add_trace(go.Scatter(y=[mahala.mean()+4*mahala.std(), mahala.mean()+4*mahala.std()], \n",
    "                                    x=[1, len(mahala)], mode='lines', name=str(conf) + ' Probability (+4 std)',\n",
    "                                    line=dict(color='red',  width=2, dash='dash')))\n",
    "    fig_mahala.update_layout(\n",
    "          title=\"Mahalanobis Distance and Possible Outliers\",\n",
    "          yaxis_title= \"<b>Mahalanobis Distance</b>\" ,\n",
    "          xaxis_title=\"<b>Tea Samples</b>\" ,\n",
    "          xaxis=dict(\n",
    "              showgrid=True,\n",
    "              showline=True,\n",
    "              showticklabels=False,\n",
    "              ticks='outside',\n",
    "              tickcolor='rgb(102, 102, 102)',\n",
    "              linecolor='rgb(102, 102, 102)',\n",
    "          ),\n",
    "          yaxis=dict(\n",
    "              showgrid=True,\n",
    "              showline=True,\n",
    "              showticklabels=True,\n",
    "              ticks='outside',\n",
    "              tickcolor='rgb(102, 102, 102)',\n",
    "              linecolor='rgb(102, 102, 102)',\n",
    "          ),    \n",
    "          margin=dict(l=40, r=40, b=40, t=40),\n",
    "          paper_bgcolor='white',\n",
    "          plot_bgcolor='white',\n",
    "          width=600, height=400,\n",
    "        )\n",
    "    fig_mahala.show()\n",
    "    \n",
    "    isKickOutliers = input('Do you want to kick outliers out? [y/n]')\n",
    "    \n",
    "    if isKickOutliers == 'y' or isKickOutliers == 'Y':\n",
    "        numout=int(input('How many outliers do you want to kick out?'))\n",
    "        PCR.KickOutliers(X=X, y=y, T=T, mahala=mahala, pc=pc, maxoutliers=numout)\n",
    "    \n",
    "    return(fig_mahala)\n",
    "\n",
    "  def KickOutliers(X, y, T, mahala, pc, maxoutliers):\n",
    "    # Sort the RMS distance from the origin in descending order (largest first)\n",
    "    rms_dist = np.sqrt(Q**2+Tsq**2)\n",
    "    \n",
    "    # Sort calibration spectra according to descending RMS distance\n",
    "    X['mahala']=mahala\n",
    "\n",
    "    Xc=X.sort_values(['mahala'], ascending=False, axis=0)\n",
    "    Xc=Xc.drop(['mahala'], axis=1)\n",
    "    X=X.drop(['mahala'], axis=1) \n",
    "\n",
    "    mahala=np.flip(np.argsort(mahala), axis=0)\n",
    "    yc = y[mahala]\n",
    "\n",
    "    # Discard one outlier at a time up to the value max_outliers\n",
    "    # and calculate the mse cross-validation of the PLS model\n",
    "    max_outliers = maxoutliers  \n",
    " \n",
    "    for j in range(max_outliers):\n",
    "      print('Removed Sample : ' + str(Xc.index[j]))\n",
    "      PCR.ModelFit(Xc[j:], yc[j:], pc, cv, testsize )\n",
    "\n",
    "\n",
    "  def ModelFit(X, y, pc, cv, testsize=0.2, figure=True):\n",
    "    ''' Principal Component Regression in Python'''\n",
    "    ''' Step 1: PCA on input data'''\n",
    "    if 'sample' in X.columns:\n",
    "       start=1\n",
    "    else:\n",
    "      start=0\n",
    "\n",
    "    # Define the PCA object\n",
    "    pca = PCA()\n",
    "    \n",
    "\n",
    "    # Run PCA producing the reduced variable Xred and select the first pc components\n",
    "    Xreg = pca.fit_transform(X.iloc[:,start:])[:,:pc]\n",
    "    \n",
    "    ''' Step 2: regression on selected principal components'''\n",
    " \n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr2 = linear_model.LinearRegression()\n",
    "    # Fit\n",
    "    regr.fit(Xreg, y)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(Xreg, y, test_size=testsize, random_state=42) \n",
    "    regr2.fit(x_train, y_train)\n",
    "\n",
    "    # Calibration\n",
    "    y_c = regr.predict(Xreg)\n",
    "    # Cross-validation\n",
    "    if cv == 'loo':\n",
    "      cv = LeaveOneOut()\n",
    "    y_cv = cross_val_predict(regr, Xreg, y, cv=cv, n_jobs=-1)\n",
    "    # Train\n",
    "    y_v = regr2.predict(x_train)\n",
    "    # Test\n",
    "    y_t = regr2.predict(x_test)\n",
    " \n",
    "    # Calculate scores for calibration and cross-validation\n",
    "    score_c = r2_score(y, y_c)\n",
    "    score_cv = r2_score(y, y_cv)\n",
    "    score_t = r2_score(y_test, y_t)\n",
    "    score_v = r2_score(y_train, y_v)\n",
    " \n",
    "    # Calculate mean square error for calibration and cross validation\n",
    "    mse_c = np.sqrt(mean_squared_error(y, y_c))\n",
    "    mse_cv = np.sqrt(mean_squared_error(y, y_cv)) \n",
    "    mse_t = np.sqrt(mean_squared_error(y_test, y_t))\n",
    "    mse_v = np.sqrt(mean_squared_error(y_train, y_v))\n",
    "\n",
    "    # plot the regression line\n",
    "    if figure==True:\n",
    "      z1 = np.polyfit(y, y_c, 1)\n",
    "      z2 = np.polyfit(y_train, y_v, 1)\n",
    "      z3 = np.polyfit(y, y_cv, 1)\n",
    "      PCR_fig = go.Figure()\n",
    "\n",
    "      PCR_fig.add_trace(go.Scatter(x=y_cv, y=y,\n",
    "                    mode='markers', marker_symbol='circle',marker_line_width=1,\n",
    "                    )) #text=X.index, textposition='middle right', name='CV'\n",
    "      PCR_fig.add_trace(go.Scatter(x=y, y=y,\n",
    "                    mode='lines', line=dict(color='rgb(102, 102, 102)', width=1, dash='dot')))\n",
    "      PCR_fig.add_trace(go.Scatter(x=np.polyval(z3,y), y=y,\n",
    "                    mode='lines', name='Model', marker_color='red'))  \n",
    "      PCR_fig.add_annotation(text=\"<i>R<sup>2</sup><sub>CV</sub></i> = \"+str(round(score_cv,2)),\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.05, y=0.99, showarrow=False)\n",
    "      PCR_fig.add_annotation(text=\"<i>RMSE<sub>CV</sub></i> = \"+str(round(mse_cv,2)),\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.05, y=0.94, showarrow=False) \n",
    "      PCR_fig.add_annotation(text=\"<i>RPD<sub>CV</sub></i> = \"+str(round(1/(mse_cv/statistics.stdev(y)),2)),\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.05, y=0.89, showarrow=False)\n",
    "      PCR_fig.add_annotation(text=\"Slope = \"+str(round(1/(np.polyfit(y, y_cv, 1)[0]),2)),\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.05, y=0.84, showarrow=False)\n",
    "    \n",
    "      PCR_fig.update_layout(\n",
    "        showlegend=False,\n",
    "        title=\"Calibration and Cross Validation\",\n",
    "        yaxis_title=\"<b>Sensorial Appereance Score</b>\",\n",
    "        xaxis_title=\"<b>Predicted Appereance Score</b>\",\n",
    "        xaxis=dict(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "            tick0 = min(y_cv),\n",
    "            dtick = 2, #75,#2\n",
    "            title_standoff = 0\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "            tick0 = min(y),\n",
    "            dtick = 2, #75,#2,\n",
    "            title_standoff = 0\n",
    "        ),  \n",
    "        width=400, height=400,\n",
    "        margin=dict(l=40, r=40, b=40, t=40),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "        \n",
    "      )\n",
    "      PCR_fig.show()\n",
    "      plotly.io.write_image(PCR_fig, \"H:\\sensorfint\\Resultsfigure.pdf\", format= 'pdf', engine='kaleido')  \n",
    "    \n",
    "    return (y_cv, score_c, score_v, score_t, score_cv, mse_c, mse_v, mse_t, mse_cv)#, regr.fit(Xreg, y).coef_, pca\n",
    "\n",
    "  def ModelCheck(X, y, pc, cv, testsize=0.2, figure=False):\n",
    "    score=np.empty(shape=(4,pc))\n",
    "    mse=np.empty(shape=(4,pc))\n",
    "    for i in range(0,pc,1):\n",
    "      score[:,i]=PCR.ModelFit(X, y, i+1, cv, testsize, False)[1:5]\n",
    "      mse[:,i]=PCR.ModelFit(X, y, i+1, cv, testsize, False)[5:]\n",
    "\n",
    "    score_fig = go.Figure()\n",
    "    score_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=score[0,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='R<sup>2</sup>'))\n",
    "    score_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=score[1,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='R<sup>2</sup>_train'))\n",
    "    score_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=score[2,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='R<sup>2</sup>_test'))\n",
    "    score_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=score[3,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='R<sup>2</sup>_CV'))\n",
    "  \n",
    "    mse_fig = go.Figure()\n",
    "    mse_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=mse[0,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='RMSE'))\n",
    "    mse_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=mse[1,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='RMSE_train'))\n",
    "    mse_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=mse[2,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='RMSE_test'))\n",
    "    mse_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=mse[3,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='RMSE_CV')) \n",
    "    score_fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=500,\n",
    "        height=500,\n",
    "        title=\"R<sup>2</sup> vs. Component Number\",\n",
    "        yaxis_title=\"R<sup>2</sup>\",\n",
    "        xaxis_title=\"Number of Components\",\n",
    "        xaxis=dict(\n",
    "            showgrid=True,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "        ),    \n",
    "        margin=dict(l=140, r=40, b=50, t=80),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "      )    \n",
    "    mse_fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=500,\n",
    "        height=500,\n",
    "        title=\"MSE vs. Component Number\",\n",
    "        yaxis_title=\"MSE\",\n",
    "        xaxis_title=\"Number of Components\",\n",
    "        xaxis=dict(\n",
    "            showgrid=True,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "        ),    \n",
    "        margin=dict(l=140, r=40, b=50, t=80),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "      )\n",
    "    score_fig.show()\n",
    "    mse_fig.show()\n",
    "    return(list(mse[-1]).index(min(mse[-1]))+1)\n",
    "\n",
    "  def wlSelection(X, y, pc, cv, testsize=0.2, testcriteria='R2test', figure=False):\n",
    "    ''' testcriteria: 'r2', 'r2train', 'r2test', r2cv',  'mse', 'msetrain', 'msetest', msecv'\n",
    "        cv= int or 'llo'   '''\n",
    "    if 'sample' in X.columns:\n",
    "       start=1\n",
    "    else:\n",
    "      start=0\n",
    "\n",
    "    '''# Define the PCA object\n",
    "    pca = PCA()\n",
    "    \n",
    "    # Run PCA producing the reduced variable Xred and select the first pc components\n",
    "    Xreg = pca.fit_transform(X.iloc[:,start:])[:,:pc]\n",
    "\n",
    "     Step 2: regression on selected principal components\n",
    " \n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "    # Fit\n",
    "    regr.fit(Xreg, y)\n",
    "    return(regr.coefficients )\n",
    "    sorted_ind = np.abs(regr.coef_[:,0])\n",
    "\n",
    "    # Sort calibration spectra according to descending RMS distance\n",
    "    Xc=X.append(pd.Series(name='sort'))\n",
    "    Xc.loc['sort']=sorted_ind\n",
    "    Xc=Xc.sort_values(['sort'], ascending=True, axis=1)\n",
    "    Xc=Xc.drop(['sort'], axis=0) '''\n",
    "    \n",
    "    X_eliminated=X.copy(deep=True)\n",
    "    if testcriteria=='r2': testnum=1\n",
    "    elif testcriteria=='r2train': testnum=2\n",
    "    elif testcriteria=='r2test': testnum=3\n",
    "    elif testcriteria=='r2cv': testnum=4\n",
    "    elif testcriteria=='mse': testnum=5\n",
    "    elif testcriteria=='msetrain': testnum=6\n",
    "    elif testcriteria=='msetest': testnum=7\n",
    "    elif testcriteria=='msecv': testnum=8\n",
    "\n",
    "    matrixlength= X_eliminated.shape[1]-pc\n",
    "    for j in range(0, X_eliminated.shape[1]-pc):\n",
    "      if testnum<5:\n",
    "        if PCR.ModelFit(X_eliminated.drop([str(X.columns[j])], axis=1), y, pc, cv, testsize, figure=False)[testnum] > PCR.ModelFit(X_eliminated.iloc[:,:], y, pc, cv, testsize, figure=False)[testnum]:\n",
    "          #print('Removed wl : ' + str(X.columns[j]))\n",
    "          X_eliminated=X_eliminated.drop([str(X.columns[j])], axis=1)\n",
    "          j -= 1\n",
    "      else: \n",
    "        if PCR.ModelFit(X_eliminated.drop([str(X.columns[j])], axis=1), y, pc, cv, testsize, figure=False)[testnum] < PCR.ModelFit(X_eliminated.iloc[:,:], y, pc, cv, testsize, figure=False)[testnum]:\n",
    "          #print('Removed wl : ' + str(X.columns[j]))\n",
    "          X_eliminated=X_eliminated.drop([str(X.columns[j])], axis=1)\n",
    "          j -= 1\n",
    "      print(str((j+1)*100/(matrixlength)) + '% completed', end='\\r', flush=True)\n",
    "    \n",
    "    PCR.ModelFit(X_eliminated.iloc[:,:], y, pc, cv, testsize, figure=True)\n",
    "    return (X_eliminated, PCR.ModelFit(X_eliminated.iloc[:,:], y, pc, cv, testsize, figure=False)[1:])    \n",
    "    \n",
    "    #return (X_eliminated, PCR.ModelFit(X_eliminated.iloc[:,:], y, pc, cv, testsize, figure=True)[1:])\n",
    "    #return (X_eliminated)\n",
    " \n",
    "\n",
    "class PLS:\n",
    "\n",
    "  def Outliers(X, y, pc, conf=0.95):\n",
    "    pls = PLSRegression(n_components=pc)\n",
    "    # Fit data\n",
    "    pls.fit(X, y)\n",
    "\n",
    "    # Get X scores\n",
    "    T = pls.x_scores_\n",
    "    # Get X loadings\n",
    "    P = pls.x_loadings_\n",
    "    # Calculate error array\n",
    "    Err = X - np.dot(T,P.T)\n",
    "    # Calculate Q-residuals (sum over the rows of the error array)\n",
    "    Q = np.sum(Err**2, axis=1)\n",
    "    # Calculate Hotelling's T-squared (note that data are normalised by default)\n",
    "    Tsq = np.sum((pls.x_scores_/np.std(pls.x_scores_, axis=0))**2, axis=1)\n",
    "\n",
    "    # Calculate confidence level for T-squared from the ppf of the F distribution\n",
    "    Tsq_conf =  f.ppf(q=conf, dfn=pc, dfd=X.shape[0])*pc*(X.shape[0]-1)/(X.shape[0]-pc)\n",
    " \n",
    "    # Estimate the confidence level for the Q-residuals\n",
    "    i = np.max(Q) + 1\n",
    "    while 1-np.sum(Q > i)/np.sum(Q > 0) > conf:\n",
    "      i -= 1\n",
    "    Q_conf = i\n",
    "\n",
    "    #draw the graph\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=Tsq, y=Q,\n",
    "                      mode='markers+text',marker_symbol='circle',marker_line_width=2, text=Q.index, textposition=\"top center\"))\n",
    "    fig.add_trace(go.Scatter(x=[Tsq_conf,Tsq_conf], y=[np.min(Q), np.max(Q)],\n",
    "                      mode='lines', line=dict(color='firebrick', width=2, dash='dash')))\n",
    "    fig.add_trace(go.Scatter(x=[np.min(Tsq), np.max(Tsq)], y=[Q_conf,Q_conf], \n",
    "                      mode='lines', line=dict(color='firebrick', width=2, dash='dash')))\n",
    "    fig.update(layout_showlegend=False)\n",
    "    fig.update_layout(\n",
    "            title=\"PLS Outliers\",\n",
    "            yaxis_title=\"Q-residuals\",\n",
    "            xaxis_title=\"Hotellingâ€™s T<sup>2</sup>\",\n",
    "            xaxis=dict(\n",
    "                showgrid=True,\n",
    "                showline=True,\n",
    "                showticklabels=True,\n",
    "                ticks='outside',\n",
    "                tickcolor='rgb(102, 102, 102)',\n",
    "                linecolor='rgb(102, 102, 102)',\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                showgrid=True,\n",
    "                showline=True,\n",
    "                showticklabels=True,\n",
    "                ticks='outside',\n",
    "                tickcolor='rgb(102, 102, 102)',\n",
    "                linecolor='rgb(102, 102, 102)',\n",
    "            ),    \n",
    "            margin=dict(l=140, r=40, b=50, t=80),\n",
    "            paper_bgcolor='white',\n",
    "            plot_bgcolor='white',\n",
    "          )\n",
    "    fig.show()\n",
    "    \n",
    "    numout=int(input('How many outliers do you want to kick out?'))\n",
    "    PLS.KickOutliers(X=X, y=y, Q=Q, Tsq=Tsq, pc=pc, maxoutliers=numout)\n",
    "\n",
    "  def KickOutliers(X, y, Q, Tsq, pc, maxoutliers):\n",
    "    # Sort the RMS distance from the origin in descending order (largest first)\n",
    "    rms_dist = np.sqrt(Q**2+Tsq**2)\n",
    "    \n",
    "    # Sort calibration spectra according to descending RMS distance\n",
    "    X['rms']=rms_dist\n",
    "    \n",
    "    Xc=X.sort_values(['rms'], ascending=False, axis=0)\n",
    "    Xc=Xc.drop(['rms'], axis=1)\n",
    "    X=X.drop(['rms'], axis=1) \n",
    "       \n",
    "    rms_dist=np.flip(np.argsort(rms_dist), axis=0)\n",
    "    yc = y[rms_dist]\n",
    "\n",
    "    # Discard one outlier at a time up to the value max_outliers\n",
    "    # and calculate the mse cross-validation of the PLS model\n",
    "    max_outliers = maxoutliers  \n",
    "\n",
    "\n",
    "    # Define empty mse array\n",
    "    mse = np.zeros(max_outliers)\n",
    " \n",
    "    for j in range(max_outliers):\n",
    "      print('Removed Sample : ' + str(Xc.index[j]))\n",
    "      PLS.ModelFit(Xc[j:], yc[j:], pc )\n",
    " \n",
    "\n",
    "  def ModelFit(X, y, pc, cv, testsize=0.2, figure=True):\n",
    "    ''' Partial Least Square Regression'''\n",
    "\n",
    "    if 'sample' in X.columns:\n",
    "       start=1\n",
    "    else:\n",
    "      start=0\n",
    "\n",
    "    # Define PLS object \n",
    "    pls = PLSRegression(n_components=pc)\n",
    "    pls2 = PLSRegression(n_components=pc)\n",
    "    \n",
    "\n",
    "    # Fit\n",
    "    pls.fit(X.iloc[:,start:], y)\n",
    "\n",
    "    #bins = np.linspace(np.floor(np.min(y)), np.ceil(np.max(y)), 5)\n",
    "    bins = np.array([10, 13, 16, 19])\n",
    "    y_binned = np.digitize(y, bins)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X.iloc[:,start:], y, test_size=testsize, random_state=42) \n",
    "    pls2.fit(x_train, y_train)\n",
    "\n",
    "    # Cross-validation\n",
    "    if cv == 'loo':\n",
    "      cv = LeaveOneOut()\n",
    "    y_cv = cross_val_predict(pls2, X.iloc[:,start:], y, cv=cv, n_jobs=-1)\n",
    "    y_cv = np.array(y_cv).flatten()\n",
    "    # Calibration\n",
    "    y_c = pls.predict(X.iloc[:,start:])\n",
    "    y_c = np.array(y_c).flatten()\n",
    "    # Train\n",
    "    y_v = pls2.predict(x_train)\n",
    "    y_v = np.array(y_v).flatten()\n",
    "    # Test\n",
    "    y_t = pls2.predict(x_test)\n",
    "    y_t = np.array(y_t).flatten()\n",
    "\n",
    "    # Calculate scores for calibration and cross-validation\n",
    "    score_c = r2_score(y, y_c)\n",
    "    score_cv = r2_score(y, y_cv)\n",
    "    score_t = r2_score(y_test, y_t)\n",
    "    score_v = r2_score(y_train, y_v)\n",
    "\n",
    "    # Calculate mean square error for calibration and cross validation\n",
    "    mse_c = np.sqrt(mean_squared_error(y, y_c)) \n",
    "    mse_cv = np.sqrt(mean_squared_error(y, y_cv))\n",
    "    mse_t = np.sqrt(mean_squared_error(y_test, y_t))\n",
    "    mse_v = np.sqrt(mean_squared_error(y_train, y_v))\n",
    "\n",
    "    # plot the regression line\n",
    "    if figure==True:\n",
    "      z1 = np.polyfit(y, y_c, 1)\n",
    "      z2 = np.polyfit(y_train, y_v, 1)\n",
    "      z3 = np.polyfit(y, y_cv, 1)\n",
    "      PCR_fig = go.Figure()\n",
    "    \n",
    "      PCR_fig.add_trace(go.Scatter(x=y_cv, y=y,\n",
    "                    mode='markers', marker_symbol='circle',marker_line_width=1,\n",
    "                    )) #text=X.index, textposition='middle right', name='CV'\n",
    "      PCR_fig.add_trace(go.Scatter(x=y, y=y,\n",
    "                    mode='lines', line=dict(color='rgb(102, 102, 102)', width=1, dash='dot')))\n",
    "\n",
    "      PCR_fig.add_trace(go.Scatter(x=np.polyval(z3,y), y=y,\n",
    "                    mode='lines', name='Model', marker_color='red'))\n",
    "     \n",
    "      PCR_fig.add_annotation(text=\"<i>R<sup>2</sup><sub>CV</sub></i> = \"+str(round(score_cv,2)),\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.05, y=0.99, showarrow=False)\n",
    "\n",
    "      PCR_fig.add_annotation(text=\"<i>RMSE<sub>CV</sub></i> = \"+str(round(mse_cv,2)),\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.05, y=0.94, showarrow=False) \n",
    "      PCR_fig.add_annotation(text=\"<i>RPD<sub>CV</sub></i> = \"+str(round(1/(mse_cv/statistics.stdev(y)),2)),\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.05, y=0.89, showarrow=False)\n",
    "      PCR_fig.add_annotation(text=\"Slope = \"+str(round(1/(np.polyfit(y, y_cv, 1)[0]),2)),\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.05, y=0.84, showarrow=False)\n",
    "    \n",
    "      PCR_fig.update_layout(\n",
    "        showlegend=False,\n",
    "        title=\"Calibration and Cross Validation\",\n",
    "        yaxis_title=\"<b>Measured Moisture Content (%, w/w)</b>\",\n",
    "        xaxis_title=\"<b>Predicted Moisture Content (%, w/w)</b>\",\n",
    "        xaxis=dict(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "            tick0 = min(y_cv),\n",
    "            dtick = 0.5, #75,#2\n",
    "            title_standoff = 0\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=False,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "            tick0 = min(y),\n",
    "            dtick = 0.5, #75,#2,\n",
    "            title_standoff = 0\n",
    "        ),  \n",
    "        width=400, height=400,\n",
    "        margin=dict(l=40, r=40, b=40, t=40),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "        \n",
    "      )     \n",
    "      PCR_fig.show()\n",
    "      plotly.io.write_image(PCR_fig, \"H:\\sensorfint\\Resultsfigure.pdf\", format= 'pdf', engine='kaleido')\n",
    "\n",
    "    return (y_cv, score_c, score_v, score_t, score_cv, mse_c, mse_v, mse_t, mse_cv)\n",
    "    \n",
    "\n",
    "  def ModelCheck(X, y, pc, cv, testsize=0.2, figure=False):\n",
    "    score=np.empty(shape=(4,pc))\n",
    "    mse=np.empty(shape=(4,pc))\n",
    "    for i in range(0,pc,1):\n",
    "      score[:,i]=PLS.ModelFit(X, y, i+1, cv, testsize, figure)[1:5]\n",
    "\n",
    "      mse[:,i]=PLS.ModelFit(X, y, i+1, cv, testsize, figure)[5:]\n",
    "\n",
    "    score_fig = go.Figure()\n",
    "    score_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=score[0,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='R<sup>2</sup>'))\n",
    "    score_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=score[1,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='R<sup>2</sup>_train'))\n",
    "    score_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=score[2,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='R<sup>2</sup>_test'))\n",
    "    score_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=score[3,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='R<sup>2</sup>_CV'))\n",
    "  \n",
    "    mse_fig = go.Figure()\n",
    "    mse_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=mse[0,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='MSE'))\n",
    "    mse_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=mse[1,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='MSE_train'))\n",
    "    mse_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=mse[2,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='MSE_test'))\n",
    "    mse_fig.add_trace(go.Scatter(x=np.arange(1, pc+1), y=mse[3,:],\n",
    "                      mode='lines+markers',\n",
    "                      name='MSE_CV'))    \n",
    "\n",
    "    score_fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=500,\n",
    "        height=500,\n",
    "        title=\"R<sup>2</sup> vs. Component Number\",\n",
    "        yaxis_title=\"R<sup>2</sup>\",\n",
    "        xaxis_title=\"Number of Components\",\n",
    "        xaxis=dict(\n",
    "            showgrid=True,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "        ),    \n",
    "        margin=dict(l=140, r=40, b=50, t=80),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "      )    \n",
    "    mse_fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=500,\n",
    "        height=500,\n",
    "        title=\"MSE vs. Component Number\",\n",
    "        yaxis_title=\"MSE\",\n",
    "        xaxis_title=\"Number of Components\",\n",
    "        xaxis=dict(\n",
    "            showgrid=True,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            showline=True,\n",
    "            showticklabels=True,\n",
    "            ticks='outside',\n",
    "            tickcolor='rgb(102, 102, 102)',\n",
    "            linecolor='rgb(102, 102, 102)',\n",
    "        ),    \n",
    "        margin=dict(l=140, r=40, b=50, t=80),\n",
    "        paper_bgcolor='white',\n",
    "        plot_bgcolor='white',\n",
    "      )    \n",
    "  \n",
    "    score_fig.show()\n",
    "    mse_fig.show() \n",
    "    return(list(mse[-1]).index(min(mse[-1]))+1)\n",
    "  \n",
    "  def wlSelection(X, y, pc, cv, testsize=0.2, testcriteria='r2cv', figure=False):\n",
    "    ''' testcriteria: 'r2', 'r2train', 'r2test', r2cv',  'mse', 'msetrain', 'msetest', msecv' \n",
    "        cv: int or 'llo' '''\n",
    "    # Get the list of indices that sorts the PLS coefficients in ascending order \n",
    "    # of the absolute value\n",
    "    pls = PLSRegression(n_components=pc)\n",
    "    # Fit data\n",
    "    pls.fit(X, y)\n",
    "    sorted_ind = np.abs(pls.coef_[:,0])\n",
    "\n",
    "    # Sort calibration spectra according to descending RMS distance\n",
    "    Xc=X.append(pd.Series(name='sort'))\n",
    "    Xc.loc['sort']=sorted_ind\n",
    "    Xc=Xc.sort_values(['sort'], ascending=True, axis=1)\n",
    "    Xc=Xc.drop(['sort'], axis=0) \n",
    "    \n",
    "    X_eliminated=Xc.copy(deep=True)\n",
    "    if testcriteria=='r2': testnum=1\n",
    "    elif testcriteria=='r2train': testnum=2\n",
    "    elif testcriteria=='r2test': testnum=3\n",
    "    elif testcriteria=='r2cv': testnum=4\n",
    "    elif testcriteria=='mse': testnum=5\n",
    "    elif testcriteria=='msetrain': testnum=6\n",
    "    elif testcriteria=='msetest': testnum=7\n",
    "    elif testcriteria=='msecv': testnum=8\n",
    "\n",
    "    for j in range(0, Xc.shape[1]-pc-1):\n",
    "        if testnum < 5:\n",
    "            if PLS.ModelFit(Xc.iloc[:,j+1:], y, pc, cv, testsize, figure=False)[testnum] > PLS.ModelFit(Xc.iloc[:,(j):], y, pc, cv,testsize, figure=False)[testnum]:\n",
    "                X_eliminated=X_eliminated.drop([str(Xc.columns[j])], axis=1)\n",
    "        else:\n",
    "            if PLS.ModelFit(Xc.iloc[:,j+1:], y, pc, cv, testsize, figure=False)[testnum] < PLS.ModelFit(Xc.iloc[:,(j):], y, pc, cv, testsize, figure=False)[testnum]:\n",
    "                X_eliminated=X_eliminated.drop([str(Xc.columns[j])], axis=1)\n",
    "        print(str((j+1)*100/(Xc.shape[1]-pc-1)) + '% completed', end='\\r', flush=True)  \n",
    "    \n",
    "    PLS.ModelFit(X_eliminated.iloc[:,:], y, pc, cv, testsize, figure=True)\n",
    "    \n",
    "    return (X_eliminated, PLS.ModelFit(X_eliminated.iloc[:,:], y, pc, cv, testsize, figure=False)[1:])    \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('H:\\sensorfint')\n",
    "filename='BrukerNewTeaSamples.csv'#'drive/My Drive/peachdata.csv' #'drive/My Drive/repeatability_plate.csv' #'drive/My Drive/BrukerNewTeaSamples.csv'\n",
    "data=pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw and Processed Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(filename)\n",
    "y=pd.DataFrame(data=data['cellulose']).set_index(data['sample']).astype('float')\n",
    "y=np.array(y.groupby(y.index)['cellulose'].mean())\n",
    "data=data.drop(['lance' , 'grade', 'colour', 'body', 'quality', 'appereance', 'density',\n",
    "                'powder', 'moisture', 'extract', 'cellulose' ], axis = 1)\n",
    "data=data.groupby(['sample']).mean()\n",
    "dataX=data.iloc[:,:]\n",
    "\n",
    "dataX.insert(0, 'sample', dataX.index)\n",
    "X=SmoothandDeriv.Derivative(dataX)\n",
    "\n",
    "fig1 = DrawSpect(dataX)\n",
    "fig2 = DrawSpect(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.io.write_image(fig1, \"H:\\sensorfint\\Results/Bruker_raw_forpub.pdf\", format= 'pdf', engine='kaleido')\n",
    "plotly.io.write_image(fig2, \"H:\\sensorfint\\Results/Bruker_1stderiv_frpub.pdf\", format= 'pdf', engine='kaleido')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeatability Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(filename)\n",
    "data=data.drop(['lance' , 'grade', 'colour', 'body', 'quality', 'appereance', 'density','powder', 'moisture', 'extract', 'cellulose' ], axis = 1)\n",
    "RMS_repeatability(data, central='mean', conf=0.95, multiplicator=1, reducename=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=RMS_graph(RMS_repeatability(data, central='mean', conf=0.95, multiplicator=10, reducename=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.io.write_image(fig, \"H:\\sensorfint\\Results/FOSS_rms_forpub.pdf\", format= 'pdf', engine='kaleido')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers detection - Option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(filename)\n",
    "y=pd.DataFrame(data=data['cellulose']).set_index(data['sample']).astype('float')\n",
    "y=pd.array(y.groupby(y.index)['cellulose'].mean())\n",
    "data=data.drop(['lance' , 'grade', 'colour', 'body', 'quality', 'appereance', 'density',\n",
    "                'powder', 'moisture', 'extract', 'cellulose' ], axis = 1)\n",
    "data=data.groupby(['sample']).mean()\n",
    "dataX=data.iloc[:,:] \n",
    "\n",
    "dataX.insert(0, 'sample', dataX.index)\n",
    "X=ScatterCorrection.MSC(SmoothandDeriv.SG(deTrend(dataX, method='highorder', order=2)))\n",
    "\n",
    "PLS.Outliers(dataX, y, 5, conf=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers detection - Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(filename)\n",
    "y=pd.DataFrame(data=data['cellulose']).set_index(data['sample']).astype('float')\n",
    "y=np.array(y.groupby(y.index)['cellulose'].mean())\n",
    "data=data.drop(['lance' , 'grade', 'colour', 'body', 'quality', 'appereance', 'density',\n",
    "                'powder', 'moisture', 'extract', 'cellulose' ], axis = 1)\n",
    "data=data.groupby(['sample']).mean()\n",
    "dataX=data.iloc[:,:] \n",
    "\n",
    "dataX.insert(0, 'sample', dataX.index)\n",
    "#X=ScatterCorrection.MSC(SmoothandDeriv.SG(deTrend(dataX, method='highorder', order=2)))\n",
    "\n",
    "\n",
    "fig=PCR.Outliers(dataX,y, 5, 'chisq', 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.io.write_image(fig, \"H:\\sensorfint\\Results/Bruker_averagedoutliers.pdf\", format= 'pdf', engine='kaleido')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCR Model Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(filename)\n",
    "y=pd.DataFrame(data=data['cellulose']).set_index(data['sample']).astype('float')\n",
    "y=np.array(y.groupby(y.index)['cellulose'].mean())\n",
    "data=data.drop(['lance' , 'grade', 'colour', 'body', 'quality', 'appereance', 'density',\n",
    "                'powder', 'moisture', 'extract', 'cellulose' ], axis = 1)\n",
    "data=data.groupby(['sample']).mean()\n",
    "dataX=data.iloc[:,:]\n",
    "\n",
    "dataX.insert(0, 'sample', dataX.index)\n",
    "X=SmoothandDeriv.RemoveSpike(ScatterCorrection.MSC(SmoothandDeriv.SG(dataX, window=5)),21)\n",
    "\n",
    "\n",
    "PCR.ModelCheck(X,y, pc=10, cv='loo', testsize=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLS Model Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(filename)\n",
    "y=pd.DataFrame(data=data['extract']).set_index(data['sample']).astype('float')\n",
    "y=np.array(y.groupby(y.index)['extract'].mean())\n",
    "\n",
    "data=data.drop(['lance' , 'grade', 'colour', 'body', 'quality', 'appereance', 'density',\n",
    "                'powder', 'moisture', 'extract', 'cellulose' ], axis = 1)\n",
    "data=data.groupby(['sample']).mean()\n",
    "dataX=data.iloc[:,:] \n",
    "\n",
    "dataX.insert(0, 'sample', dataX.index)\n",
    "X=SmoothandDeriv.RemoveSpike(ScatterCorrection.MSC(SmoothandDeriv.SG(dataX, window=5)),21)\n",
    "\n",
    "PLS.ModelCheck(X,y, pc=10, cv='loo', testsize=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLS Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(filename)\n",
    "y=pd.DataFrame(data=data['cellulose']).set_index(data['sample']).astype('float')\n",
    "y=np.array(y.groupby(y.index)['cellulose'].mean())\n",
    "data=data.drop(['lance' , 'grade', 'colour', 'body', 'quality', 'appereance', 'density',\n",
    "                'powder', 'moisture', 'extract', 'cellulose' ], axis = 1)\n",
    "data=data.groupby(['sample']).mean()\n",
    "dataX=data.iloc[:,336:-272] \n",
    "\n",
    "dataX.insert(0, 'sample', dataX.index)\n",
    "\n",
    "X=ScatterCorrection.MSC(SmoothandDeriv.SG(dataX, window=11, polyorder=2, derivorder=1))\n",
    "\n",
    "PLS.ModelFit(X,y,3,cv='loo', testsize=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCR Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(filename)\n",
    "#data=data.loc[data['sample'] != 2020]\n",
    "\n",
    "y=pd.DataFrame(data=data['cellulose']).set_index(data['sample']).astype('float')\n",
    "\n",
    "y=pd.array(y.groupby(y.index)['cellulose'].mean())\n",
    "data=data.drop(['lance' , 'grade', 'colour', 'body', 'quality', 'appereance', 'density',\n",
    "                'powder', 'moisture', 'extract', 'cellulose' ], axis = 1)\n",
    "data=data.groupby(['sample']).mean()\n",
    "\n",
    "dataX=data.iloc[:,500:-12] \n",
    "\n",
    "dataX.insert(0, 'sample', dataX.index)\n",
    "X=ScatterCorrection.SNV(SmoothandDeriv.SG(dataX, window=11, polyorder=2, derivorder=1))\n",
    "\n",
    "PCR.ModelFit(X,y,11, cv='loo', testsize=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimum Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_variable='cellulose'\n",
    "\n",
    "data=pd.read_csv(filename)\n",
    "\n",
    "y=pd.DataFrame(data=data[test_variable]).set_index(data['sample']).astype('float')\n",
    "y=np.array(y.groupby(y.index)[test_variable].mean())\n",
    "\n",
    "data=data.drop(['lance' , 'grade', 'colour', 'body', 'quality', 'appereance', 'density',\n",
    "                'powder', 'moisture', 'extract', 'cellulose' ], axis = 1)\n",
    "data=data.groupby(['sample']).mean()\n",
    "dataX=data.iloc[:,475:]          \n",
    "\n",
    "dataX.insert(0, 'sample', dataX.index)\n",
    "\n",
    "window=max(round(dataX.shape[1]*0.005) if round(dataX.shape[1]*0.005)%2==1 else round(dataX.shape[1]*0.005)+1, 3)\n",
    "datas=[dataX,\n",
    "       ScatterCorrection.MSC(dataX.iloc[:,:], reference='mean'),\n",
    "       ScatterCorrection.MSC(dataX.iloc[:,:], reference='median'),\n",
    "       ScatterCorrection.MinMaxNorm(dataX), \n",
    "       ScatterCorrection.Normalisation(dataX),\n",
    "       ScatterCorrection.SNV(dataX),\n",
    "       SmoothandDeriv.NW(dataX, window=window),\n",
    "       SmoothandDeriv.SG(dataX, window=window, polyorder=1),\n",
    "       SmoothandDeriv.SG(dataX, window=window, polyorder=2),\n",
    "       deTrend(dataX, method='linregres'),\n",
    "       deTrend(dataX, method='simple'),\n",
    "       deTrend(dataX, method='highorder', order=2),\n",
    "       ScatterCorrection.MSC(ScatterCorrection.MSC(dataX, reference='mean'), reference='mean'),\n",
    "       ScatterCorrection.MSC(ScatterCorrection.MSC(dataX, reference='median'), reference='median'),\n",
    "       ScatterCorrection.MSC(SmoothandDeriv.SG(dataX, window=window, polyorder=1), reference='mean'),\n",
    "       ScatterCorrection.MSC(SmoothandDeriv.SG(dataX, window=window, polyorder=2), reference='mean'),\n",
    "       ScatterCorrection.MSC(SmoothandDeriv.SG(dataX, window=window, polyorder=1), reference='median'),\n",
    "       ScatterCorrection.MSC(SmoothandDeriv.SG(dataX, window=window, polyorder=2), reference='median'),\n",
    "       ScatterCorrection.MSC(SmoothandDeriv.NW(dataX, window=window), reference='mean'),\n",
    "       ScatterCorrection.MSC(SmoothandDeriv.NW(dataX, window=window), reference='median'),\n",
    "       ScatterCorrection.SNV(SmoothandDeriv.SG(dataX, window=window, polyorder=1)),\n",
    "       ScatterCorrection.SNV(SmoothandDeriv.SG(dataX, window=window, polyorder=2)),\n",
    "       ScatterCorrection.SNV(SmoothandDeriv.NW(dataX, window=window)),\n",
    "       ScatterCorrection.Normalisation(SmoothandDeriv.SG(dataX, window=window, polyorder=1)),\n",
    "       ScatterCorrection.Normalisation(SmoothandDeriv.SG(dataX, window=window, polyorder=2)),\n",
    "       ScatterCorrection.Normalisation(SmoothandDeriv.NW(dataX, window=window)),\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"FOSS_processeddata.txt\", \n",
    "           datas,\n",
    "           delimiter =\", \", \n",
    "           fmt ='% s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations=['All Data (Noise Removed)', 'MSC_mean', 'MSC_median', 'MinMaxNorm', 'Normalisation', \n",
    "                                    'SNV', 'NW', 'SG_order1', 'SG_order2', 'deTrending_linregres', 'deTrending_simple', \n",
    "                                    'deTrending_highorder2', 'MSC+MSC_mean', 'MSC+MSC_median', 'MSC_mean+SG_order1', 'MSC_mean+SG_order2', \n",
    "                                    'MSC_median+SG_order1', 'MSC_median+SG_order2', 'MSC_mean+NW', 'MSC_median+NW', 'SNV+SG_order1', \n",
    "                                    'SNV+SG_order2', 'SNV+NW', 'Normalisation+SG_order1', 'Normalisation+SG_order2', 'Normalisation+NW']\n",
    "goodnessoffit=pd.DataFrame(columns = ['R2', 'R2_train', 'R2_test', 'R2_CV', 'RMSE', 'RMSE_train', 'RMSE_test', 'RMSE_CV', 'Number of PCs', 'wL'],\n",
    "                           index = combinations )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_variable='moisture'\n",
    "testsize=0.2\n",
    "cv='loo'\n",
    "\n",
    "data=pd.read_csv(filename)\n",
    "\n",
    "y=pd.DataFrame(data=data[test_variable]).set_index(data['sample']).astype('float')\n",
    "y=np.array(y.groupby(y.index)[test_variable].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations=['All Data (Noise Removed)', 'MSC_mean', 'MSC_median', 'MinMaxNorm', 'Normalisation', \n",
    "                                    'SNV', 'NW', 'SG_order1', 'SG_order2', 'deTrending_linregres', 'deTrending_simple', \n",
    "                                    'deTrending_highorder2', 'MSC+MSC_mean', 'MSC+MSC_median', 'MSC_mean+SG_order1', 'MSC_mean+SG_order2', \n",
    "                                    'MSC_median+SG_order1', 'MSC_median+SG_order2', 'MSC_mean+NW', 'MSC_median+NW', 'SNV+SG_order1', \n",
    "                                    'SNV+SG_order2', 'SNV+NW', 'Normalisation+SG_order1', 'Normalisation+SG_order2', 'Normalisation+NW']\n",
    "goodnessoffit=pd.DataFrame(columns = ['R2', 'R2_train', 'R2_test', 'R2_CV', 'RMSE', 'RMSE_train', 'RMSE_test', 'RMSE_CV', 'Number of PCs', 'wL'],\n",
    "                           index = combinations )\n",
    "\n",
    "regression_method='PLSR'\n",
    "for goodnessoffit_index in range(7,8):\n",
    "    if  goodnessoffit_index!=0 and 'FOSS' in filename:\n",
    "        X=SmoothandDeriv.RemoveSpike(datas[goodnessoffit_index],21)\n",
    "    else:\n",
    "        X=datas[goodnessoffit_index]\n",
    "\n",
    "    stop=False    \n",
    "    pc=PLS.ModelCheck(X,y, pc=10, cv=cv, testsize=0.2)\n",
    "    out1=PLS.wlSelection(X,y,pc=pc, cv=cv, testsize=0.2, testcriteria='msecv')\n",
    "    best_goodness=out1\n",
    "    counter=3\n",
    "    while stop==False:\n",
    "        out2=PLS.wlSelection(out1[0],y,pc=pc, cv=cv, testsize=0.2, testcriteria='msecv')\n",
    "        if best_goodness[1][7]<=out2[1][7]:\n",
    "            if counter == 0:\n",
    "                stop=True\n",
    "                goodnessoffit.iloc[goodnessoffit_index,:-2]=best_goodness[1:][0]\n",
    "                goodnessoffit.iloc[goodnessoffit_index,-2]=pc\n",
    "                goodnessoffit.iloc[goodnessoffit_index,-1]=pd.array(best_goodness[0].columns[1:])\n",
    "            else:\n",
    "                counter -= 1\n",
    "                out1=out2\n",
    "        else:\n",
    "            counter==3\n",
    "            out1=out2\n",
    "            best_goodness=out2       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=PLS.ModelFit(best_goodness[0], y, pc, cv, testsize, figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations=['All Data (Noise Removed)', 'MSC_mean', 'MSC_median', 'MinMaxNorm', 'Normalisation', \n",
    "                                    'SNV', 'NW', 'SG_order1', 'SG_order2', 'deTrending_linregres', 'deTrending_simple', \n",
    "                                    'deTrending_highorder2', 'MSC+MSC_mean', 'MSC+MSC_median', 'MSC_mean+SG_order1', 'MSC_mean+SG_order2', \n",
    "                                    'MSC_median+SG_order1', 'MSC_median+SG_order2', 'MSC_mean+NW', 'MSC_median+NW', 'SNV+SG_order1', \n",
    "                                    'SNV+SG_order2', 'SNV+NW', 'Normalisation+SG_order1', 'Normalisation+SG_order2', 'Normalisation+NW']\n",
    "goodnessoffit=pd.DataFrame(columns = ['R2', 'R2_train', 'R2_test', 'R2_CV', 'RMSE', 'RMSE_train', 'RMSE_test', 'RMSE_CV', 'Number of PCs', 'wL'],\n",
    "                           index = combinations )\n",
    "\n",
    "regression_method='PCR'\n",
    "for goodnessoffit_index in range(24,25):\n",
    "    if  goodnessoffit_index!=0 and 'FOSS' in filename:\n",
    "        X=SmoothandDeriv.RemoveSpike(datas[goodnessoffit_index],21)\n",
    "    else:\n",
    "        X=datas[goodnessoffit_index]\n",
    "\n",
    "    stop=False    \n",
    "    pc=PCR.ModelCheck(X,y, pc=10, cv=cv, testsize=0.2)\n",
    "    out1=PCR.wlSelection(X,y,pc=pc, cv=cv, testsize=0.2, testcriteria='msecv')\n",
    "    best_goodness=out1\n",
    "    counter=3\n",
    "    while stop==False:\n",
    "        out2=PCR.wlSelection(out1[0],y,pc=pc, cv=cv, testsize=0.2, testcriteria='msecv')\n",
    "        if best_goodness[1][7]<=out2[1][7]:\n",
    "            if counter == 0:\n",
    "                stop=True\n",
    "                goodnessoffit.iloc[goodnessoffit_index,:-2]=best_goodness[1:][0]\n",
    "                goodnessoffit.iloc[goodnessoffit_index,-2]=pc\n",
    "                goodnessoffit.iloc[goodnessoffit_index,-1]=pd.array(best_goodness[0].columns[1:])\n",
    "            else:\n",
    "                counter -= 1\n",
    "                out1=out2\n",
    "        else:\n",
    "            counter==3\n",
    "            out1=out2\n",
    "            best_goodness=out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model=PCR.ModelFit(best_goodness[0], y, pc, cv, testsize, figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.io.write_image(fig, \"H:\\sensorfint\\Results/Bruker_averagedoutliers.pdf\", format= 'pdf', engine='kaleido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[10].explained_variance_[3]/model[10].explained_variance_ratio[:9].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(min(y),min(model[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
